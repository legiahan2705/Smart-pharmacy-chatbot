# --- 1. CÃ€I Äáº¶T THÆ¯ VIá»†N ---
!pip install -qU langchain langchain-core langchain-community langchain-google-genai google-generativeai faiss-cpu langchain-text-splitters
import json
import os
# --- THÃŠM 2 DÃ’NG NÃ€Y Äá»‚ CHá»NG TREO MÃY TRÃŠN KAGGLE ---
os.environ["USE_TF"] = "0"    # Cáº¥m load TensorFlow

import time
from langchain_core.documents import Document
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_google_genai import GoogleGenerativeAIEmbeddings 
from kaggle_secrets import UserSecretsClient 

print("ğŸš€ Báº¯t Ä‘áº§u quÃ¡ trÃ¬nh vector hÃ³a dá»¯ liá»‡u (FULL DETAIL VERSION)...")

# --- 2. Cáº¤U HÃŒNH ---
# Kiá»ƒm tra láº¡i Ä‘Æ°á»ng dáº«n file input cá»§a báº¡n
JSON_FILE_PATH = "/kaggle/input/data-longchau/longchau_selected.json" 
VECTOR_STORE_PATH = "/kaggle/working/faiss_index"

# --- 3. KHá»I Táº O API & MODEL ---
print("ğŸ”‘ Äang láº¥y API Key...")
# try:
#     user_secrets = UserSecretsClient()
#     api_key = user_secrets.get_secret("GOOGLE_API_KEY")
#     os.environ["GOOGLE_API_KEY"] = api_key
# except Exception as e:
#     print("âŒ Lá»–I: ChÆ°a cáº¥u hÃ¬nh Secret 'GOOGLE_API_KEY'.")
#     raise e

# DÃN TRá»°C TIáº¾P API KEY Má»šI VÃ€O ÄÃ‚Y (Náº±m trong ngoáº·c kÃ©p)
api_key = "" 
os.environ["GOOGLE_API_KEY"] = api_key

print("â³ Äang táº£i mÃ´ hÃ¬nh Google Embeddings (gemini-embedding-001)...")
embeddings = GoogleGenerativeAIEmbeddings(model="models/gemini-embedding-001")

# --- 4. Äá»ŒC Dá»® LIá»†U & Táº O CONTENT CHI TIáº¾T ---
print(f"ğŸ“‚ Äang Ä‘á»c dá»¯ liá»‡u tá»« file: {JSON_FILE_PATH}")
documents = []

try:
    with open(JSON_FILE_PATH, "r", encoding="utf-8") as f:
        data_array = json.load(f) 
        
    # ... (code Ä‘á»c file json á»Ÿ Pháº§n 4)
    print(f"   -> TÃ¬m tháº¥y {len(data_array)} dÃ²ng dá»¯ liá»‡u thÃ´.")
    
    # CHIáº¾N THUáº¬T CHIA Äá»‚ TRá»Š: Cháº¡y Ä‘á»£t 1 (Tá»« 501 Ä‘áº¿n 1000)
    data_array = data_array[0:500] 
    
    print(f"   -> Äang cháº¡y Äá»¢T 1: Xá»­ lÃ½ {len(data_array)} sáº£n pháº©m.")
    
    for product in data_array:
        try:
            # 1. Láº¥y thÃ´ng tin cÆ¡ báº£n
            name = product.get("TÃªn thuá»‘c") or product.get("product_name") or ""
            if not name: continue 

            # 2. Láº¥y thÃ´ng tin chi tiáº¿t (Æ¯u tiÃªn tiáº¿ng Viá»‡t, fallback sang tiáº¿ng Anh)
            # HÃ m get an toÃ n: láº¥y value, náº¿u k cÃ³ tráº£ vá» chuá»—i rá»—ng
            # --- CODE Má»šI: QUÃ‰T KEY THÃ”NG MINH ---
            # HÃ m tÃ¬m value dá»±a trÃªn tá»« khÃ³a báº¯t Ä‘áº§u (startswith)
            def get_dynamic_key(item_dict, prefix):
                for k, v in item_dict.items():
                    if str(k).startswith(prefix):
                        return str(v).strip()
                return ""

            # DÃ¹ng hÃ m má»›i Ä‘á»ƒ quÃ©t cÃ¡c key hay bá»‹ Ä‘á»•i tÃªn
            danh_muc = product.get("Danh má»¥c") or product.get("category") or ""
            
            # QuÃ©t "ThÃ nh pháº§n cá»§a..."
            thanh_phan = get_dynamic_key(product, "ThÃ nh pháº§n").replace("ThÃ´ng tin thÃ nh pháº§n HÃ m lÆ°á»£ng", "")
            
            # QuÃ©t "CÃ´ng dá»¥ng cá»§a..."
            cong_dung = get_dynamic_key(product, "CÃ´ng dá»¥ng")
            
            # QuÃ©t "CÃ¡ch dÃ¹ng..." hoáº·c "Liá»u dÃ¹ng..."
            lieu_dung = get_dynamic_key(product, "CÃ¡ch dÃ¹ng") or get_dynamic_key(product, "Liá»u dÃ¹ng")
            
            # CÃ¡c key cá»‘ Ä‘á»‹nh thÃ¬ dÃ¹ng .get() bÃ¬nh thÆ°á»ng
            tac_dung_phu = product.get("TÃ¡c dá»¥ng phá»¥", "")
            luu_y = product.get("LÆ°u Ã½", "")
            chong_chi_dinh = product.get("Chá»‘ng chá»‰ Ä‘á»‹nh", "")
            bao_quan = product.get("Báº£o quáº£n", "")
            
            nha_san_xuat = product.get("NhÃ  sáº£n xuáº¥t", "")
            nuoc_san_xuat = product.get("NÆ°á»›c sáº£n xuáº¥t", "")
            xuat_xu = product.get("Xuáº¥t xá»© thÆ°Æ¡ng hiá»‡u", "")
            dang_bao_che = product.get("Dáº¡ng bÃ o cháº¿", "")
            quy_cach = product.get("Quy cÃ¡ch", "")
            # -------------------------------------

            # 3. XÃ¢y dá»±ng Page Content "SiÃªu Ä‘áº§y Ä‘á»§"
            # AI sáº½ Ä‘á»c Ä‘oáº¡n vÄƒn báº£n nÃ y Ä‘á»ƒ tráº£ lá»i. CÃ ng chi tiáº¿t cÃ ng tá»‘t.
            page_content = f"""
            TÃªn sáº£n pháº©m: {name}
            Danh má»¥c: {danh_muc}
            Dáº¡ng bÃ o cháº¿: {dang_bao_che}
            Quy cÃ¡ch Ä‘Ã³ng gÃ³i: {quy_cach}
            Xuáº¥t xá»©: ThÆ°Æ¡ng hiá»‡u {xuat_xu}, Sáº£n xuáº¥t táº¡i {nuoc_san_xuat} bá»Ÿi {nha_san_xuat}.

            THÃ€NH PHáº¦N:
            {thanh_phan}

            CÃ”NG Dá»¤NG & CHá»ˆ Äá»ŠNH:
            {cong_dung}

            CÃCH DÃ™NG & LIá»€U DÃ™NG:
            {lieu_dung}

            CHá»NG CHá»ˆ Äá»ŠNH (KhÃ´ng dÃ¹ng cho):
            {chong_chi_dinh}

            LÆ¯U Ã & THáº¬N TRá»ŒNG (Cáº£nh bÃ¡o an toÃ n):
            {luu_y}

            TÃC Dá»¤NG PHá»¤ CÃ“ THá»‚ Gáº¶P:
            {tac_dung_phu}
            
            Báº¢O QUáº¢N:
            {bao_quan}
            """.strip()

            # 4. Metadata (DÃ¹ng Ä‘á»ƒ lá»c náº¿u cáº§n, hoáº·c hiá»ƒn thá»‹ UI)
            metadata = {
                "source": name,
                "price": str(product.get("GiÃ¡ bÃ¡n") or product.get("price_VND") or "0"),
                "origin": xuat_xu
            }
            
            doc = Document(page_content=page_content, metadata=metadata)
            documents.append(doc)
            
        except Exception as e:
            continue 

except FileNotFoundError:
    print(f"âŒ KHÃ”NG TÃŒM THáº¤Y FILE Táº I: {JSON_FILE_PATH}")
    exit()

if len(documents) == 0:
    print("âŒ Cáº¢NH BÃO: KhÃ´ng xá»­ lÃ½ Ä‘Æ°á»£c sáº£n pháº©m nÃ o.")
    exit()

print(f"âœ… ÄÃ£ chuáº©n hÃ³a FULL DATA cho {len(documents)} sáº£n pháº©m.")

# Chia nhá» vÄƒn báº£n
# TÄƒng chunk_size lÃªn 1500 vÃ¬ content bÃ¢y giá» ráº¥t dÃ i
text_splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=200)
split_docs = text_splitter.split_documents(documents)
print(f"ğŸ“¦ ÄÃ£ chia thÃ nh {len(split_docs)} chunks.")

# --- 5. Táº O VECTOR INDEX (CÆ  CHáº¾ AUTO-RETRY Báº¤T Tá»¬) ---
print("âš¡ Báº¯t Ä‘áº§u táº¡o Vector Index (Google Version)...")
start_time = time.time()

try:
    batch_size = 50
    vector_db = None
    
    total_batches = (len(split_docs) + batch_size - 1) // batch_size
    print(f"ğŸ“¦ Dá»¯ liá»‡u Ä‘Æ°á»£c chia thÃ nh {total_batches} lÃ´ Ä‘á»ƒ xá»­ lÃ½ an toÃ n.")

    for i in range(0, len(split_docs), batch_size):
        batch = split_docs[i : i + batch_size]
        current_batch = (i // batch_size) + 1
        
        print(f"   -> Äang nhÃºng (embedding) lÃ´ {current_batch}/{total_batches}...")
        
        # --- VÃ’NG Láº¶P RETRY: Káº» thÃ¹ cá»§a lá»—i 429 ---
        # --- VÃ’NG Láº¶P RETRY: Káº» thÃ¹ cá»§a lá»—i 429 ---
        max_retries = 5
        for attempt in range(max_retries):
            try:
                if vector_db is None:
                    vector_db = FAISS.from_documents(batch, embeddings)
                else:
                    temp_db = FAISS.from_documents(batch, embeddings)
                    vector_db.merge_from(temp_db)
                
                # Náº¾U THÃ€NH CÃ”NG -> ThoÃ¡t vÃ²ng láº·p retry, Ä‘i tá»›i lÃ´ tiáº¿p theo
                break 
                
            except Exception as e:
                error_msg = str(e)
                if "429" in error_msg or "RESOURCE_EXHAUSTED" in error_msg:
                    print(f"      â³ QuÃ¡ táº£i (429) á»Ÿ lÃ´ {current_batch}... (Láº§n {attempt + 1}/{max_retries})")
                    
                    # Náº¾U THá»¬ 5 Láº¦N VáºªN CHáº¾T -> Háº¾T QUOTA NGÃ€Y -> Cá»¨U Dá»® LIá»†U & Dá»ªNG Háº²N
                    if attempt == max_retries - 1:
                        print("ğŸš¨ BÃO Äá»˜NG Äá»: Háº¾T QUOTA NGÃ€Y! Dá»ªNG TOÃ€N Bá»˜ CHÆ¯Æ NG TRÃŒNH!")
                        if vector_db is not None:
                            vector_db.save_local(VECTOR_STORE_PATH)
                            !zip -r faiss_index_partial.zip {VECTOR_STORE_PATH}
                            print("âœ… ÄÃ£ lÆ°u kháº©n cáº¥p thÃ nh cÃ´ng: faiss_index_partial.zip")
                        raise Exception("ÄÃ£ cáº¡n kiá»‡t API Key. ChÆ°Æ¡ng trÃ¬nh tá»± há»§y Ä‘á»ƒ trÃ¡nh treo mÃ¡y vÃ´ Ã­ch.")
                        
                    time.sleep(60) 
                else:
                    print(f"      âŒ Lá»—i láº¡ á»Ÿ lÃ´ {current_batch}: {error_msg}")
                    break
        
        # Ngá»§ nháº¹ 5 giÃ¢y giá»¯a cÃ¡c lÃ´ bÃ¬nh thÆ°á»ng Ä‘á»ƒ khÃ´ng dá»“n dáº­p
        time.sleep(5) 
        
    # LÆ¯U FILE CUá»I CÃ™NG
    if vector_db is not None:
        vector_db.save_local(VECTOR_STORE_PATH)
        
        end_time = time.time()
        print("-" * 50)
        print(f"ğŸ‰ THÃ€NH CÃ”NG! FAISS Index Ä‘Ã£ Ä‘Æ°á»£c táº¡o xong.")
        print(f"â±ï¸ Thá»i gian: {((end_time - start_time) / 60):.2f} phÃºt")
        print("-" * 50)
        
        # NÃ©n file láº¡i
        !zip -r faiss_index.zip {VECTOR_STORE_PATH}
        print("âœ… ÄÃ£ nÃ©n xong: faiss_index.zip. Báº N CÃ“ THá»‚ Táº¢I Vá»€ Rá»’I!")
    else:
        print("âŒ Tháº¥t báº¡i: KhÃ´ng cÃ³ dá»¯ liá»‡u nÃ o Ä‘Æ°á»£c lÆ°u.")
        
except Exception as e:
    print(f"âŒ Lá»—i há»‡ thá»‘ng: {e}")