import os
import json
import gc
from dotenv import load_dotenv
from typing import TypedDict, Literal

# --- FastAPI Imports ---
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel 

# --- LangChain Imports ---
from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings, HarmBlockThreshold, HarmCategory
from langchain_community.vectorstores import FAISS
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser, JsonOutputParser
from langgraph.graph import StateGraph, END
from langgraph.checkpoint.memory import MemorySaver
import pandas as pd
import re

# =======================================================
# 0. KH·ªûI T·∫†O & C·∫§U H√åNH
# =======================================================
load_dotenv()
app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000", "http://127.0.0.1:3000"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# =======================================================
# 1. X·ª¨ L√ù D·ªÆ LI·ªÜU (D√ôNG PARQUET ƒê·ªÇ TƒÇNG T·ªêC KH·ªûI ƒê·ªòNG)
# =======================================================
import gc # Th∆∞ vi·ªán d·ªçn d·∫πp r√°c b·ªô nh·ªõ

def load_and_clean_data():
    parquet_path = "data/optimized_db.parquet"
    source_json_path = "data/longchau_selected.json"

    # 1. Load Cache (∆Øu ti√™n)
    if os.path.exists(parquet_path):
        print("‚ö° [Pandas] T√¨m th·∫•y Cache Parquet. ƒêang t·∫£i...")
        try:
            return pd.read_parquet(parquet_path)
        except Exception as e:
            print(f"‚ö†Ô∏è Cache l·ªói ({e}), s·∫Ω x·ª≠ l√Ω l·∫°i t·ª´ ƒë·∫ßu...")

    # 2. X·ª≠ l√Ω l·∫ßn ƒë·∫ßu (T·ªëi ∆∞u b·ªô nh·ªõ)
    print("üê¢ [Pandas] B·∫Øt ƒë·∫ßu ƒë·ªçc file JSON...")
    try:
        # B∆∞·ªõc A: ƒê·ªçc file
        with open(source_json_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        print(f"   -> ƒê√£ ƒë·ªçc xong {len(data)} s·∫£n ph·∫©m. ƒêang chu·∫©n h√≥a d·ªØ li·ªáu...")

        # B∆∞·ªõc B: X·ª≠ l√Ω tr·ª±c ti·∫øp tr√™n bi·∫øn 'data' (Kh√¥ng t·∫°o b·∫£n sao normalized_data)
        for item in data:
            # L·∫•y danh s√°ch key ƒë·ªÉ tr√°nh l·ªói runtime khi dictionary thay ƒë·ªïi size
            keys = list(item.keys()) 
            for key in keys:
                if key.startswith("Th√†nh ph·∫ßn"):
                    item["Th√†nh ph·∫ßn"] = item.pop(key) # ƒê·ªïi t√™n key c≈© th√†nh m·ªõi v√† x√≥a key c≈© ngay
                elif key.startswith("C√¥ng d·ª•ng"):
                    item["C√¥ng d·ª•ng"] = item.pop(key)

        print("   -> ƒêang chuy·ªÉn sang DataFrame...")
        
        # B∆∞·ªõc C: T·∫°o DataFrame v√† X√ìA NGAY bi·∫øn data ƒë·ªÉ gi·∫£i ph√≥ng RAM
        df = pd.DataFrame(data)
        del data # X√≥a bi·∫øn data
        gc.collect() # √âp bu·ªôc d·ªçn d·∫πp b·ªô nh·ªõ ngay l·∫≠p t·ª©c
        
        print("   -> ƒêang l√†m s·∫°ch c·ªôt gi√° v√† ƒëi·ªÅn d·ªØ li·ªáu thi·∫øu...")
        
        # B∆∞·ªõc D: X·ª≠ l√Ω c·ªôt gi√° (D√πng vectorized operation nhanh h∆°n apply)
        # Chuy·ªÉn v·ªÅ string tr∆∞·ªõc ƒë·ªÉ tr√°nh l·ªói
        df['Gi√° b√°n'] = df['Gi√° b√°n'].astype(str)
        # D√πng Regex tr√≠ch xu·∫•t s·ªë tr·ª±c ti·∫øp (nhanh h∆°n loop)
        df['price_int'] = df['Gi√° b√°n'].str.replace(r'[^\d]', '', regex=True)
        df['price_int'] = pd.to_numeric(df['price_int'], errors='coerce').fillna(0).astype(int)

        # B∆∞·ªõc E: ƒêi·ªÅn d·ªØ li·ªáu tr·ªëng
        cols_to_fill = ['Nh√† s·∫£n xu·∫•t', 'N∆∞·ªõc s·∫£n xu·∫•t', 'Xu·∫•t x·ª© th∆∞∆°ng hi·ªáu', 'Danh m·ª•c', 'D·∫°ng b√†o ch·∫ø', 'Quy c√°ch', 'Th√†nh ph·∫ßn', 'L∆∞u √Ω', 'B·∫£o qu·∫£n', 'C√¥ng d·ª•ng', 'ƒê∆°n v·ªã']
        
        # Ch·ªâ ƒëi·ªÅn nh·ªØng c·ªôt th·ª±c s·ª± t·ªìn t·∫°i trong df
        existing_cols = [c for c in cols_to_fill if c in df.columns]
        df[existing_cols] = df[existing_cols].fillna('')
        
        # B∆∞·ªõc F: Chuy·ªÉn ƒë·ªïi ki·ªÉu d·ªØ li·ªáu ƒë·ªÉ l∆∞u Parquet an to√†n
        print("   -> ƒêang l∆∞u Cache Parquet (B∆∞·ªõc cu·ªëi)...")
        
        # Chuy·ªÉn t·∫•t c·∫£ v·ªÅ string (tr·ª´ price_int) ƒë·ªÉ tr√°nh l·ªói format c·ªßa Parquet
        for col in df.columns:
            if col != 'price_int':
                df[col] = df[col].astype(str)
        
        # L∆∞u file
        df.to_parquet(parquet_path, index=False)
        print(f"‚úÖ [Pandas] X·ª≠ l√Ω xong v√† ƒë√£ l∆∞u Cache v√†o {parquet_path}.")
        
        return df

    except Exception as e:
        print(f"‚ùå L·ªñI NGHI√äM TR·ªåNG KHI X·ª¨ L√ù DATA: {e}")
        # Tr·∫£ v·ªÅ DataFrame r·ªóng ƒë·ªÉ server kh√¥ng b·ªã crash h·∫≥n
        return pd.DataFrame()

global_df = load_and_clean_data()

# =======================================================
# 2. MODELS & VECTORSTORE
# =======================================================
# D√πng Flash ƒë·ªÉ nhanh, temperature th·∫•p ƒë·ªÉ ch√≠nh x√°c
llm = ChatGoogleGenerativeAI(
    model="gemini-2.5-flash", 
    temperature=0,
    safety_settings={HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE} 
)

print("‚è≥ ƒêang t·∫£i m√¥ h√¨nh Embeddings...")
embeddings = GoogleGenerativeAIEmbeddings(model="models/text-embedding-004", google_api_key=os.environ.get("GOOGLE_API_KEY"))

def load_vectorstore():
    index_path = "faiss_index"
    if os.path.exists(index_path):
        try:
            return FAISS.load_local(index_path, embeddings, allow_dangerous_deserialization=True)
        except Exception as e:
            print(f"L·ªói load FAISS: {e}")
            return None
    return None

vectorstore = load_vectorstore()
if vectorstore:
    # TƒÉng t·ªëc b·∫±ng c√°ch l·ªçc b·ªõt r√°c ngay t·ª´ ƒë·∫ßu (score_threshold)
    retriever = vectorstore.as_retriever(search_kwargs={"k": 15, "score_threshold": 0.4})
else:
    print("‚ö†Ô∏è Kh√¥ng c√≥ Vectorstore!")

# =======================================================
# 3. CORE LOGIC (T·ªêI ∆ØU H√ìA: ONE-SHOT BRAIN)
# =======================================================

class AppState(TypedDict):
    question: str
    chat_history: list[str]
    intent_data: dict # Ch·ª©a k·∫øt qu·∫£ ph√¢n t√≠ch g·ªôp (Safety + Route + Keyword)
    context: str | None
    answer: str | None

# --- MESSAGES ---
EMPATHETIC_SAFETY_MESSAGE = """T√¥i kh√¥ng th·ªÉ cung c·∫•p th√¥ng tin v·ªÅ c√°ch s·ª≠ d·ª•ng thu·ªëc ƒë·ªÉ g√¢y h·∫°i cho b·∫£n th√¢n. C√°c lo·∫°i thu·ªëc ch·ªâ an to√†n khi ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë√∫ng li·ªÅu l∆∞·ª£ng theo ch·ªâ d·∫´n c·ªßa b√°c sƒ© ho·∫∑c d∆∞·ª£c sƒ©. Vi·ªác s·ª≠ d·ª•ng qu√° li·ªÅu c√≥ th·ªÉ g√¢y nguy hi·ªÉm nghi√™m tr·ªçng ƒë·∫øn s·ª©c kh·ªèe v√† t√≠nh m·∫°ng.

N·∫øu b·∫°n ƒëang g·∫∑p kh√≥ khƒÉn ho·∫∑c c√≥ √Ω ƒë·ªãnh t·ª± t·ª≠, xin h√£y t√¨m ki·∫øm s·ª± gi√∫p ƒë·ª° ngay l·∫≠p t·ª©c. C√≥ r·∫•t nhi·ªÅu ngu·ªìn h·ªó tr·ª£ s·∫µn s√†ng l·∫Øng nghe v√† gi√∫p ƒë·ª° b·∫°n. B·∫°n c√≥ th·ªÉ li√™n h·ªá v·ªõi c√°c ƒë∆∞·ªùng d√¢y n√≥ng h·ªó tr·ª£ t√¢m l√Ω ho·∫∑c n√≥i chuy·ªán v·ªõi ng∆∞·ªùi th√¢n, b·∫°n b√®, ho·∫∑c chuy√™n gia y t·∫ø.

M·ªôt s·ªë ƒë∆∞·ªùng d√¢y n√≥ng h·ªó tr·ª£ t√¢m l√Ω t·∫°i Vi·ªát Nam m√† b·∫°n c√≥ th·ªÉ li√™n h·ªá:
* T·ªïng ƒë√†i qu·ªëc gia b·∫£o v·ªá tr·∫ª em 111
* T·ªïng ƒë√†i t∆∞ v·∫•n s·ª©c kh·ªèe t√¢m th·∫ßn 1900 561203
* Ho·∫∑c t√¨m ki·∫øm s·ª± h·ªó tr·ª£ t·ª´ c√°c b·ªánh vi·ªán, ph√≤ng kh√°m chuy√™n khoa t√¢m th·∫ßn g·∫ßn nh·∫•t.

H√£y nh·ªõ r·∫±ng b·∫°n kh√¥ng ƒë∆°n ƒë·ªôc v√† c√≥ s·ª± gi√∫p ƒë·ª° d√†nh cho b·∫°n."""

# --- NODE 1: "THE BRAIN" (G·ªòP SAFETY + ROUTER + EXPANSION) ---
# Prompt n√†y ch·ª©a ƒê·∫¶Y ƒê·ª¶ c√°c √Ω t·ª´ code c≈© c·ªßa b·∫°n, nh∆∞ng g·ªôp l·∫°i ƒë·ªÉ ch·∫°y 1 l·∫ßn.
brain_prompt_template = """
B·∫°n l√† b·ªô n√£o trung t√¢m c·ªßa h·ªá th·ªëng AI y t·∫ø Long Ch√¢u. Nhi·ªám v·ª• c·ªßa b·∫°n l√† ph√¢n t√≠ch c√¢u h·ªèi v√† tr·∫£ v·ªÅ k·∫øt qu·∫£ d∆∞·ªõi d·∫°ng JSON.

H√ÉY TH·ª∞C HI·ªÜN 3 B∆Ø·ªöC PH√ÇN T√çCH SAU:

B∆Ø·ªöC 1: KI·ªÇM DUY·ªÜT AN TO√ÄN (SAFETY CHECK)
Ph√¢n t√≠ch xem c√¢u h·ªèi c√≥ ch·ª©a √Ω ƒë·ªãnh nguy hi·ªÉm kh√¥ng d·ª±a tr√™n c√°c ti√™u ch√≠:
1. T·ª± t·ª≠, t·ª± h·∫°i (Self-harm): Mu·ªën ch·∫øt, t√¨m c√°ch k·∫øt th√∫c cu·ªôc s·ªëng, ng·ªß m√£i m√£i.
2. ƒê·∫ßu ƒë·ªôc, Gi·∫øt ng∆∞·ªùi (Violence): T√¨m thu·ªëc ƒë·ªôc, thu·ªëc kh√¥ng m√†u kh√¥ng m√πi, c√°ch h·∫°i ng∆∞·ªùi.
3. S·ª≠ d·ª•ng sai m·ª•c ƒë√≠ch nghi√™m tr·ªçng: D√πng thu·ªëc qu√° li·ªÅu ƒë·ªÉ "ph√™", g√¢y m√™.
-> N·∫øu vi ph·∫°m: ƒê·∫∑t "is_unsafe": true.

B∆Ø·ªöC 2: ƒê·ªäNH TUY·∫æN (ROUTING)
X√°c ƒë·ªãnh lo·∫°i c√¢u h·ªèi ƒë·ªÉ ch·ªçn ngu·ªìn d·ªØ li·ªáu:
- N·∫øu h·ªèi th√¥ng tin m√¥ t·∫£, c√¥ng d·ª•ng, c√°ch d√πng, t√°c d·ª•ng ph·ª•, th√†nh ph·∫ßn -> Ch·ªçn "vector_search".
- N·∫øu h·ªèi GI√Å C·∫¢ (r·∫ª nh·∫•t, ƒë·∫Øt nh·∫•t), S·ªê L∆Ø·ª¢NG (bao nhi√™u lo·∫°i), SO S√ÅNH gi√°, ho·∫∑c L·ªåC theo ti√™u ch√≠ -> Ch·ªçn "structured_analysis".
-> G√°n gi√° tr·ªã v√†o tr∆∞·ªùng "route".

B∆Ø·ªöC 3: M·ªû R·ªòNG C√ÇU H·ªéI (QUERY EXPANSION)
Chuy·ªÉn ƒë·ªïi c√¢u h·ªèi th√†nh t·ª´ kh√≥a t√¨m ki·∫øm chuy√™n s√¢u:
1. Lu√¥n th√™m t·ª´ kh√≥a "Thu·ªëc", "ƒêi·ªÅu tr·ªã", "D∆∞·ª£c ph·∫©m".
2. N·∫øu m√¥ t·∫£ tri·ªáu ch·ª©ng, th√™m t√™n c√°c HO·∫†T CH·∫§T (Active Ingredients) ph·ªï bi·∫øn.
3. ƒê·ªçc L·ªãch s·ª≠ tr√≤ chuy·ªán ƒë·ªÉ gi·∫£i quy·∫øt ƒë·∫°i t·ª´ nh√¢n x∆∞ng (n√≥, thu·ªëc n√†y) n·∫øu c·∫ßn.
-> G√°n k·∫øt qu·∫£ v√†o tr∆∞·ªùng "keywords".

INPUT DATA:
History: {chat_history}
Question: {question}

OUTPUT JSON FORMAT (Kh√¥ng ƒë∆∞·ª£c ph√©p tr·∫£ v·ªÅ Markdown, ch·ªâ JSON thu·∫ßn):
{{
    "is_unsafe": boolean,
    "route": "vector_search" | "structured_analysis",
    "keywords": "string"
}}
"""
brain_chain = PromptTemplate.from_template(brain_prompt_template) | llm | JsonOutputParser()

async def brain_node(state: AppState):
    print("--- üß† THE BRAIN IS THINKING (One-Shot) ---")
    question = state["question"]
    # Ch·ªâ l·∫•y 4 c√¢u g·∫ßn nh·∫•t ƒë·ªÉ prompt kh√¥ng qu√° d√†i nh∆∞ng v·∫´n ƒë·ªß context
    history = "\n".join(state.get("chat_history", [])[-4:]) 
    
    # Keyword check nhanh (L·ªõp th·ªß c√¥ng)
    danger_keywords = ["t·ª± t·ª≠", "mu·ªën ch·∫øt", "t·ª± s√°t", "li·ªÅu ch·∫øt", "t·ª± v·∫´n", "quy√™n sinh", "ƒë·∫ßu ƒë·ªôc", "c·∫Øt c·ªï", "u·ªëng thu·ªëc ƒë·ªôc"]
    if any(k in question.lower() for k in danger_keywords):
        print("!!! SAFETY TRIGGERED (KEYWORD) !!!")
        return {"intent_data": {"is_unsafe": True, "route": "none", "keywords": ""}}

    # AI Check (L·ªõp th√¥ng minh)
    try:
        result = await brain_chain.ainvoke({"question": question, "chat_history": history})
        print(f"Brain Analysis: {result}")
        return {"intent_data": result}
    except Exception as e:
        print(f"Brain Error: {e}. Fallback to vector search.")
        # Fallback an to√†n n·∫øu l·ªói JSON
        return {"intent_data": {"is_unsafe": False, "route": "vector_search", "keywords": question}}

# --- NODE 2: RETRIEVE ---
async def retrieve_node(state: AppState):
    print("--- üîç RETRIEVE ---")
    query = state["intent_data"].get("keywords", state["question"])
    print(f"Searching: {query}")
    docs = await retriever.ainvoke(query)
    
    # Format docs
    context = "\n\n".join([doc.page_content for doc in docs])
    return {"context": context}

# --- NODE 3: PANDAS (Prompt ƒê·∫ßy ƒê·ªß C≈©) ---
pandas_prompt_template = """
B·∫°n c√≥ m·ªôt pandas DataFrame t√™n l√† `df` ch·ª©a d·ªØ li·ªáu thu·ªëc.
C√°c c·ªôt quan tr·ªçng c·∫ßn d√πng: 
- 'T√™n thu·ªëc'
- 'price_int' (Gi√° b√°n d·∫°ng s·ªë nguy√™n. 0 nghƒ©a l√† "Li√™n h·ªá nh√† thu·ªëc").
- 'Gi√° b√°n' (Gi√° d·∫°ng chu·ªói hi·ªÉn th·ªã, v√≠ d·ª•: "570.000ƒë").
- 'Danh m·ª•c' (V√≠ d·ª•: "D·∫ßu c√°, Omega 3, DHA", "Thu·ªëc gi·∫£m ƒëau").
- 'Xu·∫•t x·ª© th∆∞∆°ng hi·ªáu' (V√≠ d·ª•: "Hoa K·ª≥", "Ph√°p").
- 'N∆∞·ªõc s·∫£n xu·∫•t' (V√≠ d·ª•: "Ba Lan", "Vi·ªát Nam").
- 'D·∫°ng b√†o ch·∫ø' (Vi√™n n√©n, Siro, Vi√™n nang m·ªÅm...).
- 'Quy c√°ch' (V√≠ d·ª•: "H·ªôp 6 V·ªâ x 20 Vi√™n").

Nhi·ªám v·ª•: Vi·∫øt M·ªòT d√≤ng code Python ƒë·ªÉ l·ªçc d·ªØ li·ªáu v√† tr·∫£ l·ªùi c√¢u h·ªèi.
K·∫øt qu·∫£ ph·∫£i ƒë∆∞·ª£c g√°n v√†o bi·∫øn `result`.

QUY T·∫ÆC QUAN TR·ªåNG:
1. Khi t√¨m "R·∫ª nh·∫•t" (nsmallest), PH·∫¢I lo·∫°i b·ªè gi√° b·∫±ng 0: `df[df['price_int'] > 0]`.
2. Khi t√¨m theo "Xu·∫•t x·ª©" (V√≠ d·ª•: Thu·ªëc M·ªπ), h√£y t√¨m trong C·∫¢ 2 C·ªòT: `Xu·∫•t x·ª© th∆∞∆°ng hi·ªáu` HO·∫∂C `N∆∞·ªõc s·∫£n xu·∫•t`.
3. Khi t√¨m theo t√™n b·ªánh/tri·ªáu ch·ª©ng (V√≠ d·ª•: ƒëau ƒë·∫ßu, b·ªï n√£o), PH·∫¢I t√¨m trong C·∫¢ 3 C·ªòT: `Danh m·ª•c` HO·∫∂C `T√™n thu·ªëc` HO·∫∂C `C√¥ng d·ª•ng`.
4. Lu√¥n hi·ªÉn th·ªã c·ªôt `Quy c√°ch` trong k·∫øt qu·∫£.

V√≠ d·ª• 1:
Question: T√¨m 3 lo·∫°i thu·ªëc Omega 3 r·∫ª nh·∫•t.
Python: result = df[(df['Danh m·ª•c'].str.contains('Omega 3', case=False, na=False)) & (df['price_int'] > 0)].nsmallest(3, 'price_int')[['T√™n thu·ªëc', 'Gi√° b√°n', 'Quy c√°ch', 'Xu·∫•t x·ª© th∆∞∆°ng hi·ªáu']].to_string()

V√≠ d·ª• 2:
Question: C√≥ bao nhi√™u lo·∫°i thu·ªëc c·ªßa M·ªπ?
Python: result = f"C√≥ {{len(df[(df['N∆∞·ªõc s·∫£n xu·∫•t'].str.contains('M·ªπ|Hoa K·ª≥|USA', case=False, na=False)) | (df['Xu·∫•t x·ª© th∆∞∆°ng hi·ªáu'].str.contains('M·ªπ|Hoa K·ª≥|USA', case=False, na=False))])}} thu·ªëc c√≥ xu·∫•t x·ª© ho·∫∑c th∆∞∆°ng hi·ªáu M·ªπ."

V√≠ d·ª• 3:
Question: Li·ªát k√™ c√°c thu·ªëc d·∫°ng Siro gi√° d∆∞·ªõi 50000.
Python: result = df[(df['D·∫°ng b√†o ch·∫ø'].str.contains('Siro', case=False, na=False)) & (df['price_int'] > 0) & (df['price_int'] < 50000)][['T√™n thu·ªëc', 'Gi√° b√°n', 'Quy c√°ch']].to_string()

Question: {question}
Python:
"""
pandas_chain = PromptTemplate.from_template(pandas_prompt_template) | llm | StrOutputParser()

async def structured_analysis_node(state: AppState):
    print("--- üêº PANDAS ANALYSIS ---")
    question = state["question"]
    code = await pandas_chain.ainvoke({"question": question})
    clean_code = code.replace("```python", "").replace("```", "").strip()
    
    local_vars = {"df": global_df, "result": None}
    try:
        exec(clean_code, {}, local_vars)
        result = local_vars["result"]
        # Convert result to string safely
        if hasattr(result, 'to_string'): final = result.to_string()
        else: final = str(result)
        final_answer = f"D·ª±a tr√™n s·ªë li·ªáu ph√¢n t√≠ch ƒë∆∞·ª£c:\n{final}"
    except Exception as e:
        final_answer = f"Xin l·ªói, t√¥i g·∫∑p l·ªói khi t√≠nh to√°n s·ªë li·ªáu: {str(e)}"
    
    return {"answer": final_answer}

# --- NODE 4: GENERATE (Prompt ƒê·∫ßy ƒê·ªß C≈©) ---
# Prompt n√†y gi·ªØ nguy√™n y h·ªát b·∫£n g·ªëc c·ªßa b·∫°n
generate_prompt_template = """
B·∫°n l√† m·ªôt tr·ª£ l√Ω t∆∞ v·∫•n thu·ªëc th√¥ng minh c·ªßa Long Ch√¢u.

NGUY√äN T·∫ÆC AN TO√ÄN TUY·ªÜT ƒê·ªêI (SAFETY GUARDRAILS):
1. T·ª∞ T·ª¨ & L√ÄM H·∫†I B·∫¢N TH√ÇN: N·∫øu ng∆∞·ªùi d√πng h·ªèi v·ªÅ li·ªÅu l∆∞·ª£ng g√¢y ch·∫øt ng∆∞·ªùi, c√°ch t·ª± t·ª≠... -> T·ª™ CH·ªêI TR·∫¢ L·ªúI.
2. QU√Å LI·ªÄU/U·ªêNG NH·∫¶M: C·∫£nh b√°o ƒëi kh√°m b√°c sƒ©, sau ƒë√≥ cung c·∫•p th√¥ng tin tham kh·∫£o t·ª´ Context.
3. KH√îNG THAY TH·∫æ B√ÅC Sƒ®: V·ªõi c√°c tri·ªáu ch·ª©ng nghi√™m tr·ªçng, khuy√™n ƒëi kh√°m ngay.
4. KH√îNG B·ªäA ƒê·∫∂T: Ch·ªâ tr·∫£ l·ªùi d·ª±a tr√™n Context v√† L·ªãch s·ª≠.

L·ªãch s·ª≠ h·ªôi tho·∫°i:
{chat_history}

Context:
{context}

Question: {question}
Answer:
"""
rag_generation_chain = PromptTemplate.from_template(generate_prompt_template) | llm | StrOutputParser()

async def generate_node(state: AppState):
    print("--- ‚úçÔ∏è GENERATE ---")
    question = state["question"]
    context = state.get("context", "")
    history = "\n".join(state.get("chat_history", []))
    
    try:
        answer = await rag_generation_chain.ainvoke({
            "question": question, 
            "context": context, 
            "chat_history": history
        })
    except Exception as e:
        print(f"Error: {e}")
        answer = "Xin l·ªói, t√¥i kh√¥ng th·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi n√†y l√∫c n√†y."
    
    # C·∫≠p nh·∫≠t l·ªãch s·ª≠
    new_history = state.get("chat_history", []) + [f"User: {question}", f"AI: {answer}"]
    return {"answer": answer, "chat_history": new_history}

async def update_history_pandas(state: AppState):
    # Node ph·ª• ƒë·ªÉ c·∫≠p nh·∫≠t l·ªãch s·ª≠ cho nh√°nh Pandas (v√¨ Pandas Node return answer tr·ª±c ti·∫øp)
    question = state["question"]
    answer = state["answer"]
    new_history = state.get("chat_history", []) + [f"User: {question}", f"AI: {answer}"]
    return {"chat_history": new_history}

# =======================================================
# 4. X√ÇY D·ª∞NG GRAPH
# =======================================================
def build_rag_agent():
    workflow = StateGraph(AppState)

    # Add Nodes
    workflow.add_node("brain", brain_node)
    workflow.add_node("retrieve", retrieve_node)
    workflow.add_node("generate", generate_node)
    workflow.add_node("structured_analysis", structured_analysis_node)
    workflow.add_node("update_history_pandas", update_history_pandas) # Node ph·ª• ƒë·ªÉ l∆∞u history

    # Entry Point
    workflow.set_entry_point("brain")

    # Routing Logic
    def route_decision(state):
        intent = state["intent_data"]
        
        # 1. N·∫øu kh√¥ng an to√†n -> End ngay (tr·∫£ l·ªùi ·ªü API handler)
        if intent.get("is_unsafe"):
            print("--- ROUTING: UNSAFE -> END ---")
            return "unsafe"
            
        # 2. ƒê·ªãnh tuy·∫øn b√¨nh th∆∞·ªùng
        route = intent.get("route")
        print(f"--- ROUTING TO: {route} ---")
        if route == "structured_analysis":
            return "structured_analysis"
        else:
            return "vector_search"

    workflow.add_conditional_edges(
        "brain",
        route_decision,
        {
            "structured_analysis": "structured_analysis",
            "vector_search": "retrieve",
            "unsafe": END
        }
    )

    # Edges
    workflow.add_edge("retrieve", "generate")
    workflow.add_edge("generate", END)
    
    # Nh√°nh Pandas: T√≠nh to√°n -> L∆∞u history -> End
    workflow.add_edge("structured_analysis", "update_history_pandas")
    workflow.add_edge("update_history_pandas", END)

    return workflow.compile(checkpointer=MemorySaver())

rag_agent = build_rag_agent()
print("üöÄ TURBO BACKEND (FULL PROMPTS) READY!")

# =======================================================
# 5. API ENDPOINT
# =======================================================
class ChatRequest(BaseModel):
    question: str
    thread_id: str = "default_user"

@app.post("/chat")
async def chat_handler(request: ChatRequest):
    print(f"--> User: {request.question}")
    config = {"configurable": {"thread_id": request.thread_id}}
    
    result = await rag_agent.ainvoke({"question": request.question}, config=config)
    
    # Ki·ªÉm tra Safety t·ª´ k·∫øt qu·∫£ Brain
    intent = result.get("intent_data", {})
    if intent.get("is_unsafe"):
        final_answer = EMPATHETIC_SAFETY_MESSAGE
    else:
        final_answer = result.get("answer", "L·ªói: Kh√¥ng c√≥ c√¢u tr·∫£ l·ªùi.")
    
    return {"answer": final_answer}